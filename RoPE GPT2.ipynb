{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "authorship_tag": "ABX9TyOW0tOPvJrZEX5Wd9syMq7r"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "RSXiOUrucBSi",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1738440325879,
     "user_tz": 300,
     "elapsed": 186058,
     "user": {
      "displayName": "Jhenner Tigreros",
      "userId": "10282691994518148206"
     }
    },
    "outputId": "f14bcb73-f18d-41ad-d091-b5d168901f47",
    "ExecuteTime": {
     "end_time": "2025-09-25T00:00:22.220930Z",
     "start_time": "2025-09-25T00:00:09.518290Z"
    }
   },
   "source": [
    "!pip install einops xformers np"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: einops in d:\\profile\\programing\\ia\\basicllmsmodels\\.venv\\lib\\site-packages (0.8.1)\n",
      "Requirement already satisfied: xformers in d:\\profile\\programing\\ia\\basicllmsmodels\\.venv\\lib\\site-packages (0.0.32.post2)\n",
      "Requirement already satisfied: np in d:\\profile\\programing\\ia\\basicllmsmodels\\.venv\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: numpy in d:\\profile\\programing\\ia\\basicllmsmodels\\.venv\\lib\\site-packages (from xformers) (2.3.3)\n",
      "Requirement already satisfied: torch==2.8.0 in d:\\profile\\programing\\ia\\basicllmsmodels\\.venv\\lib\\site-packages (from xformers) (2.8.0)\n",
      "Requirement already satisfied: filelock in d:\\profile\\programing\\ia\\basicllmsmodels\\.venv\\lib\\site-packages (from torch==2.8.0->xformers) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in d:\\profile\\programing\\ia\\basicllmsmodels\\.venv\\lib\\site-packages (from torch==2.8.0->xformers) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in d:\\profile\\programing\\ia\\basicllmsmodels\\.venv\\lib\\site-packages (from torch==2.8.0->xformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in d:\\profile\\programing\\ia\\basicllmsmodels\\.venv\\lib\\site-packages (from torch==2.8.0->xformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in d:\\profile\\programing\\ia\\basicllmsmodels\\.venv\\lib\\site-packages (from torch==2.8.0->xformers) (3.1.6)\n",
      "Requirement already satisfied: fsspec in d:\\profile\\programing\\ia\\basicllmsmodels\\.venv\\lib\\site-packages (from torch==2.8.0->xformers) (2025.9.0)\n",
      "Requirement already satisfied: setuptools in d:\\profile\\programing\\ia\\basicllmsmodels\\.venv\\lib\\site-packages (from torch==2.8.0->xformers) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\profile\\programing\\ia\\basicllmsmodels\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch==2.8.0->xformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\profile\\programing\\ia\\basicllmsmodels\\.venv\\lib\\site-packages (from jinja2->torch==2.8.0->xformers) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules import ModuleList\n",
    "from torch.nn.modules.normalization import LayerNorm\n",
    "from torch import nn, einsum, broadcast_tensors\n",
    "from einops import rearrange, repeat\n",
    "\n",
    "\n",
    "import copy\n",
    "import math"
   ],
   "metadata": {
    "id": "wJjFQShadGTx",
    "ExecuteTime": {
     "end_time": "2025-09-25T00:02:15.348136Z",
     "start_time": "2025-09-25T00:02:15.325329Z"
    }
   },
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-25T00:02:19.788595Z",
     "start_time": "2025-09-25T00:02:19.778724Z"
    }
   },
   "cell_type": "code",
   "source": "torch.cuda.is_available()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "id": "gu3RiwkfeXJU"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "device"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mfXyaTFSoVI7",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1738440330789,
     "user_tz": 300,
     "elapsed": 4,
     "user": {
      "displayName": "Jhenner Tigreros",
      "userId": "10282691994518148206"
     }
    },
    "outputId": "b7450e14-d958-4413-ee0e-39390740df27"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def _get_clones(module, n):\n",
    "    return ModuleList([copy.deepcopy(module) for i in range(n)])"
   ],
   "metadata": {
    "id": "FlUvCj4dfE1y"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class Conv1D(nn.Module):\n",
    "    def __init__(self, nx, nf):\n",
    "        '''\n",
    "        nx: Numero de datos de entrada.\n",
    "        nf: Numero de filtros. (Canales de salida).\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.nf = nf\n",
    "        #Inicializando una matriz vacia de pesos del tamaño (nx)X(nf)\n",
    "        w = torch.empty(nx, nf)\n",
    "        #Inicializando los pesos con una distribución normal.\n",
    "        nn.init.normal_(w, std=0.02)\n",
    "        #Calculando los pesos y sesgos encodeandos usando nn.Parameter\n",
    "        self.weight = nn.Parameter(w)\n",
    "        self.bias = nn.Parameter(torch.zeros(nf))\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''x:Tensor de entrada.'''\n",
    "        #El tamaño de la salida es la suna de la segunda dimensión de X y el número de filtros nf.\n",
    "        size_out = x.size()[:-1] + (self.nf,)\n",
    "        # Producot punto Q,K(Transpuesta) y V\n",
    "        x = torch.addmm(self.bias, x.view(-1, x.size(-1)), self.weight)# x.view ayuda a calcular la transpuesta.\n",
    "        x = x.view(*size_out)\n",
    "        return x"
   ],
   "metadata": {
    "id": "Kfp70gl_fHoL"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dropout, d_model=768, nx=768*4):\n",
    "        super().__init__()\n",
    "        self.c_fc    = Conv1D(d_model, nx)\n",
    "        self.c_proj  = Conv1D(nx, d_model)\n",
    "        self.act     = F.gelu\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.dropout(self.c_proj(self.act(self.c_fc(x))))"
   ],
   "metadata": {
    "id": "Xms1IIJUfO8j"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def exists(val):\n",
    "    return val is not None\n",
    "\n",
    "def default(val, d):\n",
    "    return val if exists(val) else d\n",
    "\n",
    "def broadcat(tensors, dim = -1):\n",
    "    broadcasted_tensors = broadcast_tensors(*tensors)\n",
    "    return torch.cat(broadcasted_tensors, dim = dim)\n",
    "\n",
    "def rotate_half(x):\n",
    "    '''The initial step of our roformer includes use of In order to generalize our results in 2D to any xi ∈ Rd\n",
    "       where d is even, we divide the d-dimension space into d/2\n",
    "       sub-spaces and combine them in the merit of the linearity of the inner product, turning f{q,k} into\n",
    "\n",
    "    Lo anterior fue un extracto del artículo que implica dividir en d/2'''\n",
    "    x = rearrange(x, '... (d r) -> ... d r', r = 2)\n",
    "    x1, x2 = x.unbind(dim = -1)\n",
    "    x = torch.stack((-x2, x1), dim = -1)\n",
    "    return rearrange(x, '... d r -> ... (d r)')\n",
    "\n",
    "def apply_rotary_emb(freqs, t, start_index = 0, scale = 1., seq_dim = -2):\n",
    "    '''\n",
    "    Una función para aplicar las rotaciones del embedding, obteniendo primero la dimensión de rotación y la longitud de la secuencia\n",
    "    obteniendo el índice final sumando el índice inicial y la dimensión de rotación como se mencionó anteriormente,\n",
    "    la t izquierda, t y t derecha con el segmento de token anterior, durante el segmento de token y después del segmento de token\n",
    "    aplica la rotación del embedding a la porción central de t.\n",
    "\n",
    "    La rotación implica una combinación de operaciones de coseno y seno utilizando las frecuencias y el factor de escala especificados.\n",
    "    '''\n",
    "    rot_dim, seq_len = freqs.shape[-1], t.shape[seq_dim]\n",
    "    freqs = freqs[-seq_len:].to(t)\n",
    "    end_index = start_index + rot_dim\n",
    "    t_left, t, t_right = t[..., :start_index], t[..., start_index:end_index], t[..., end_index:]\n",
    "    t = (t * freqs.cos() * scale) + (rotate_half(t) * freqs.sin() * scale)\n",
    "    return torch.cat((t_left, t, t_right), dim = -1)\n",
    "\n",
    "def apply_learned_rotations(rotations, t, start_index = 0, freq_ranges = None):\n",
    "    '''\n",
    "    Aprendizaje de rotaciones mediante el manejo de frecuencias mediante la ampliación de las rotaciones,\n",
    "    esta reorganización ayuda a combinar las rotaciones en una sola, ahora se repiten las rotaciones replicando\n",
    "    las rotaciones y luego se aplican las rotaciones de embeddings.'''\n",
    "    if exists(freq_ranges):\n",
    "        rotations = einsum('..., f -> ... f', rotations, freq_ranges)\n",
    "        rotations = rearrange(rotations, '... r f -> ... (r f)')\n",
    "\n",
    "    rotations = repeat(rotations, '... n -> ... (n r)', r = 2)\n",
    "    return apply_rotary_emb(rotations, t, start_index = start_index)"
   ],
   "metadata": {
    "id": "pBazlB0VigKQ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class RotaryEmbedding(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        theta = 10000,\n",
    "        max_freq = 10,\n",
    "        num_freqs = 1,\n",
    "        interpolate_factor = 1.,\n",
    "        theta_rescale_factor = 1.,\n",
    "    ):\n",
    "        '''Esta es un constructor del RoPE\n",
    "        theta: El angulo de rotación\n",
    "        max_freq: La frecuencia maxima de rotación\n",
    "        num_freq: El numero de veces la frecuencia necesaria para ser iterado.\n",
    "        interpolate factor: Un factor usado para controlar el valor del Positional Embedding si es mayor o menor.\n",
    "        theta_rescale_factor: Como el valor theta decae a medida que aprende necesitamos reescalarlo en ese proceso.\n",
    "        '''\n",
    "        super().__init__()\n",
    "        theta *= theta_rescale_factor ** (dim / (dim - 2))\n",
    "\n",
    "\n",
    "        freqs = 1. / (theta ** (torch.arange(0, dim, 2)[:(dim // 2)].float() / dim))\n",
    "\n",
    "        self.cache = dict()\n",
    "        self.cache_scale = dict()\n",
    "        self.freqs = nn.Parameter(freqs)\n",
    "\n",
    "\n",
    "        # Dimesión base para la sequencia.\n",
    "        self.default_seq_dim = -2\n",
    "\n",
    "        # Factores de interpolación.\n",
    "        assert interpolate_factor >= 1.\n",
    "        self.interpolate_factor = interpolate_factor\n",
    "\n",
    "        # xpos\n",
    "        self.register_buffer('scale', None)\n",
    "\n",
    "\n",
    "        scale = (torch.arange(0, dim, 2) + 0.4 * dim) / (1.4 * dim)\n",
    "        self.register_buffer('scale', scale)\n",
    "\n",
    "    def get_seq_pos(self, seq_len, device, dtype, offset = 0):\n",
    "        '''\n",
    "        La función para obtener la sequencial posicional del embeding usando torch.arange\n",
    "        que usa [end-start]/start dividido por el factor de interpolación. para controlar\n",
    "        su valor.\n",
    "         '''\n",
    "        return (torch.arange(seq_len, device = device, dtype = dtype) + offset) / self.interpolate_factor\n",
    "\n",
    "    def rotate_queries_or_keys(self, t, seq_dim = None, offset = 0, freq_seq_len = None):\n",
    "        '''Función para operar la rotación sobre las queries y keys.'''\n",
    "        seq_dim = default(seq_dim, self.default_seq_dim)\n",
    "\n",
    "\n",
    "        device, dtype, seq_len = t.device, t.dtype, t.shape[seq_dim]\n",
    "\n",
    "        if exists(freq_seq_len):\n",
    "            assert freq_seq_len >= seq_len\n",
    "            seq_len = freq_seq_len\n",
    "\n",
    "        freqs = self.forward(lambda: self.get_seq_pos(seq_len, device = device, dtype = dtype, offset = offset), cache_key = f'freqs:{seq_len}|offset:{offset}')\n",
    "\n",
    "        if seq_dim == -3:\n",
    "            freqs = rearrange(freqs, 'n d -> n 1 d')\n",
    "\n",
    "        return apply_rotary_emb(freqs, t, seq_dim = seq_dim)\n",
    "\n",
    "    def forward(self, t, cache_key = None):\n",
    "        '''Función para propagar el valor T.'''\n",
    "        should_cache = exists(cache_key)\n",
    "\n",
    "        if should_cache and cache_key in self.cache:\n",
    "            return self.cache[cache_key]\n",
    "\n",
    "        if callable(t):\n",
    "            t = t()\n",
    "\n",
    "        freqs = self.freqs\n",
    "\n",
    "        freqs = einsum('..., f -> ... f', t.type(freqs.dtype), freqs) #Convirtiendo las frequencias en la transpuesta.\n",
    "        freqs = repeat(freqs, '... n -> ... (n r)', r = 2)\n",
    "\n",
    "        if should_cache:\n",
    "            self.cache[cache_key] = freqs\n",
    "\n",
    "        return freqs"
   ],
   "metadata": {
    "id": "EGPJxAQiihEa"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, d_model=768, n_head=12, n_ctx=1024, d_head=64, bias=True, scale=False):\n",
    "        '''Función de construcción\n",
    "        Params:\n",
    "        d_model:Dimensión que necesita ser ingresada en el modelo.\n",
    "        n_head:La cantidad de heads de atención.\n",
    "        n_ctx:Buffer para guardar los registros del sesgo.\n",
    "        d_head:Dimesión de salida para el head.\n",
    "        bias:Un booleano para saber si incluir el sesgo.\n",
    "        scale: Escalar y estabilidad númerica (sqrt(dk))\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.n_head  = n_head\n",
    "        self.d_model = d_model\n",
    "        self.c_attn  = Conv1D(d_model, d_model*3)\n",
    "        self.scale   = scale\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.register_buffer(\"bias\", torch.tril(torch.ones(n_ctx, n_ctx)).view(1, 1, n_ctx, n_ctx))\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.c_proj  = Conv1D(d_model, d_model)\n",
    "        self.rotate = RotaryEmbedding(dim=32)\n",
    "\n",
    "    def split_heads(self, x):\n",
    "        \"\"\"\n",
    "        Diviendo en la cantidad de heads y retornando.\n",
    "        return shape [`batch`, `head`, `sequence`, `features`]\n",
    "        \"\"\"\n",
    "        new_shape = x.size()[:-1] + (self.n_head, x.size(-1)//self.n_head)\n",
    "        x = x.view(*new_shape)\n",
    "        return x.permute(0, 2, 1, 3)\n",
    "\n",
    "    def _attn(self, q, k, v, attn_mask=None):\n",
    "        \"\"\"Función de antención principal.\n",
    "        Que calcula usando la formula de producto punto de atención.\"\"\"\n",
    "        scores  = torch.matmul(q, k.transpose(-2, -1))# producto punto de Q*K(t)\n",
    "        if self.scale: scores = scores/math.sqrt(v.size(-1))# escalandola por sqrt(dk)\n",
    "        nd, ns  = scores.size(-2), scores.size(-1)\n",
    "        if attn_mask is not None: scores = scores + attn_mask# agregando los valores con la mascara de atención.\n",
    "        scores  = self.softmax(scores)# añadiendo los valores de softmax\n",
    "        scores  = self.dropout(scores) # función de dropout 0.1\n",
    "        outputs = torch.matmul(scores, v) # Multiplicación final del puntaje por V.\n",
    "        return outputs\n",
    "\n",
    "    def merge_heads(self, x):\n",
    "        # Combinando todas las heads en una sola.\n",
    "        x = x.permute(0, 2, 1, 3).contiguous()\n",
    "        new_shape = x.size()[:-2] + (x.size(-2)*x.size(-1),)\n",
    "        return x.view(*new_shape)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''Función de para calcular atención, separar las heads y combinarlas de nuevo.'''\n",
    "        x        = self.c_attn(x) #new `x` shape - `[1,3,2304]`\n",
    "        q, k, v  = x.split(self.d_model, dim=2)\n",
    "        q, k, v  = self.split_heads(q), self.split_heads(k), self.split_heads(v)\n",
    "        q = self.rotate.rotate_queries_or_keys(q)\n",
    "        k = self.rotate.rotate_queries_or_keys(k)\n",
    "        out      = self._attn(q, k, v)\n",
    "        out      = self.merge_heads(out)\n",
    "        out      = self.c_proj(out)\n",
    "        return out"
   ],
   "metadata": {
    "id": "uravxQVpfZ4S",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1738441762698,
     "user_tz": 300,
     "elapsed": 373,
     "user": {
      "displayName": "Jhenner Tigreros",
      "userId": "10282691994518148206"
     }
    }
   },
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model=768, n_head=12, dropout=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.attn        = Attention(d_model=768, n_head=12, d_head=64, n_ctx=1024, bias=True, scale=False)\n",
    "        self.feedforward = FeedForward(dropout=0.1, d_model=768, nx=768*4)\n",
    "        self.ln_1        = LayerNorm(d_model)\n",
    "        self.ln_2        = LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.ln_1(x))\n",
    "        x = x + self.feedforward(self.ln_2(x))\n",
    "        return x"
   ],
   "metadata": {
    "id": "6tSwyE6QfiLP",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1738441764586,
     "user_tz": 300,
     "elapsed": 391,
     "user": {
      "displayName": "Jhenner Tigreros",
      "userId": "10282691994518148206"
     }
    }
   },
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class GPT2(nn.Module):\n",
    "    def __init__(self, nlayers=12, n_ctx=1024, d_model=768, vcb_sz=50257):\n",
    "        '''nlayer: La cantidad de veces que queremos multiplicar el Transformer.\n",
    "        n_ctx: El contexto, la cantidad total de tokens que puede ver en el pasado de las palabras.\n",
    "        d_model:Dimesionos del modelo.\n",
    "        vcb_sz:El tamaño del vocabulario usado en el entrenamiento.'''\n",
    "        super(GPT2, self).__init__()\n",
    "        self.nlayers = nlayers\n",
    "        block        = TransformerBlock(d_model=768, n_head=12, dropout=0.1)\n",
    "        self.h       = _get_clones(block, 12)\n",
    "        self.wte     = nn.Embedding(vcb_sz, d_model)\n",
    "        self.wpe     = nn.Embedding(n_ctx, d_model)\n",
    "        self.drop    = nn.Dropout(0.1)\n",
    "        self.ln_f    = LayerNorm(d_model)\n",
    "        self.out     = nn.Linear(d_model, vcb_sz, bias=False)\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        '''Inicialización de los pesos.'''\n",
    "        self.out.weight = self.wte.weight\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        '''Inicialización con la media y S.D.'''\n",
    "        if isinstance(module, (nn.Linear, nn.Embedding, Conv1D)):\n",
    "            module.weight.data.normal_(mean=0.0, std=0.02)\n",
    "            if isinstance(module, (nn.Linear, Conv1D)) and module.bias is not None:\n",
    "                '''Data Bias zero'''\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "\n",
    "    def forward(self, src, labels=None, pos_ids=None):\n",
    "        '''Añadir el embedding posicional, dropping y añadiendo los inputs\n",
    "           usados por la función de perdida y finalmente añadiendo la salida y la\n",
    "           perdida.'''\n",
    "        if pos_ids is None:\n",
    "            pos_ids = torch.arange(0, src.size(-1)).unsqueeze(0)\n",
    "        pos_ids = pos_ids.to(src.device)  # Asegurarse que los pos_ids están en el mismo device.\n",
    "        inp = self.drop((self.wte(src) + self.wpe(pos_ids)))\n",
    "        for i in range(self.nlayers): inp = self.h[i](inp)\n",
    "        inp     = self.ln_f(inp)\n",
    "        logits  = self.out(inp)\n",
    "        outputs = (logits,) + (inp,)\n",
    "\n",
    "        if labels is not None:\n",
    "            shift_logits = logits[..., :-1, :].contiguous()\n",
    "            shift_labels = labels[..., 1:].contiguous()\n",
    "            loss = self.loss_fn(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
    "            outputs = (loss,) + outputs\n",
    "            return loss.mean()\n",
    "        return logits"
   ],
   "metadata": {
    "id": "Cm2dD9KyflYi",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1738441766521,
     "user_tz": 300,
     "elapsed": 1,
     "user": {
      "displayName": "Jhenner Tigreros",
      "userId": "10282691994518148206"
     }
    }
   },
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch.nn.functional as F\n",
    "import time\n",
    "from transformers import GPT2Tokenizer"
   ],
   "metadata": {
    "id": "Q1mPKZxdftI6",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1738441771235,
     "user_tz": 300,
     "elapsed": 507,
     "user": {
      "displayName": "Jhenner Tigreros",
      "userId": "10282691994518148206"
     }
    }
   },
   "execution_count": 29,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model = GPT2()"
   ],
   "metadata": {
    "id": "ZuoC4itMfxqz"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!curl --output gpt2-pytorch_model_rope.bin --location https://huggingface.co/Zuckerbird/RoPE-gpt2/resolve/main/pytorch_model.bin"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kmKHsWiHf7e9",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1738441812104,
     "user_tz": 300,
     "elapsed": 12213,
     "user": {
      "displayName": "Jhenner Tigreros",
      "userId": "10282691994518148206"
     }
    },
    "outputId": "e6f90822-7881-4d24-cb46-227f2358e8c3"
   },
   "execution_count": 30,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  1188  100  1188    0     0   3772      0 --:--:-- --:--:-- --:--:--  3783\n",
      "100 1431M  100 1431M    0     0   119M      0  0:00:11  0:00:11 --:--:--  236M\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model_dict = model.state_dict()\n",
    "state_dict = torch.load(\"./gpt2-pytorch_model_rope.bin\")\n",
    "\n",
    "old_keys = []\n",
    "new_keys = []\n",
    "for key in state_dict.keys():\n",
    "    if \"mlp\" in key: #El diccionario de estado para el MLP feedforward debe ser cambiado por mlp\n",
    "        new_key = key.replace(\"mlp\", \"feedforward\")\n",
    "        new_keys.append(new_key)\n",
    "        old_keys.append(key)"
   ],
   "metadata": {
    "id": "Bqw4UaZKgLrm",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1738441843278,
     "user_tz": 300,
     "elapsed": 1762,
     "user": {
      "displayName": "Jhenner Tigreros",
      "userId": "10282691994518148206"
     }
    }
   },
   "execution_count": 31,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for old_key, new_key in zip(old_keys, new_keys):\n",
    "    state_dict[new_key]=state_dict.pop(old_key)"
   ],
   "metadata": {
    "id": "3r3EXVWNgV5A",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1738441846740,
     "user_tz": 300,
     "elapsed": 349,
     "user": {
      "displayName": "Jhenner Tigreros",
      "userId": "10282691994518148206"
     }
    }
   },
   "execution_count": 32,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "pretrained_dict = {k: v for k, v in state_dict.items() if k in model_dict}\n",
    "\n",
    "model_dict.update(pretrained_dict)\n",
    "model.load_state_dict(model_dict)\n",
    "model.eval()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Z_H4pVIgX3D",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1738441848016,
     "user_tz": 300,
     "elapsed": 751,
     "user": {
      "displayName": "Jhenner Tigreros",
      "userId": "10282691994518148206"
     }
    },
    "outputId": "05686872-ed51-4308-8a2d-4b119aa21470"
   },
   "execution_count": 33,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GPT2(\n",
       "  (h): ModuleList(\n",
       "    (0-11): 12 x TransformerBlock(\n",
       "      (attn): Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (softmax): Softmax(dim=-1)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (c_proj): Conv1D()\n",
       "      )\n",
       "      (feedforward): FeedForward(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (wte): Embedding(50257, 768)\n",
       "  (wpe): Embedding(1024, 768)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       "  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (out): Linear(in_features=768, out_features=50257, bias=False)\n",
       "  (loss_fn): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())"
   ],
   "metadata": {
    "id": "YllyrazTgeG8",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1738441851982,
     "user_tz": 300,
     "elapsed": 1,
     "user": {
      "displayName": "Jhenner Tigreros",
      "userId": "10282691994518148206"
     }
    }
   },
   "execution_count": 34,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "size_bytes = total_params * 4\n",
    "size_mb = size_bytes / (1024 ** 2)\n",
    "\n",
    "print(f\"El tamaño total de GPT2 sin alteraciones es: {size_bytes} bytes o {size_mb:.2f} MB\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7DZCeOM8gf8h",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1738441853067,
     "user_tz": 300,
     "elapsed": 410,
     "user": {
      "displayName": "Jhenner Tigreros",
      "userId": "10282691994518148206"
     }
    },
    "outputId": "49f54d09-ff43-414a-9887-664bf4a2645a"
   },
   "execution_count": 35,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "El tamaño total de GPT2 sin alteraciones es: 497759232 bytes o 474.70 MB\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "context = torch.tensor([tokenizer.encode(\"The planet earth is a beautiful\")])"
   ],
   "metadata": {
    "id": "voxmoWW3go6l",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1738441865166,
     "user_tz": 300,
     "elapsed": 771,
     "user": {
      "displayName": "Jhenner Tigreros",
      "userId": "10282691994518148206"
     }
    }
   },
   "execution_count": 36,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def generate(context, ntok=550):\n",
    "    start_time = time.time()\n",
    "    for _ in range(ntok):\n",
    "        out = model(context)\n",
    "        logits = out[:, -1, :]\n",
    "        indices_to_remove = logits < torch.topk(logits, 10)[0][..., -1, None]\n",
    "        logits[indices_to_remove] = -np.inf\n",
    "        next_tok = torch.multinomial(F.softmax(logits, dim=-1), num_samples=1).squeeze(1)\n",
    "        context = torch.cat([context, next_tok.unsqueeze(-1)], dim=-1)\n",
    "    end_time = time.time()\n",
    "    inference_time = end_time - start_time\n",
    "    return context, inference_time"
   ],
   "metadata": {
    "id": "StTNnLCbg1xM",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1738441869346,
     "user_tz": 300,
     "elapsed": 348,
     "user": {
      "displayName": "Jhenner Tigreros",
      "userId": "10282691994518148206"
     }
    }
   },
   "execution_count": 37,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "out, inference_time = generate(context, ntok=40)\n",
    "decoded_output = tokenizer.decode(out[0])"
   ],
   "metadata": {
    "id": "1JzzXApkg_oP",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1738441877355,
     "user_tz": 300,
     "elapsed": 6401,
     "user": {
      "displayName": "Jhenner Tigreros",
      "userId": "10282691994518148206"
     }
    }
   },
   "execution_count": 38,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(f\"Inference Time: {inference_time:.4f} seconds\")\n",
    "print(f\"Generated Output: {decoded_output}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_LUY2n9IiBS8",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1738441877355,
     "user_tz": 300,
     "elapsed": 1,
     "user": {
      "displayName": "Jhenner Tigreros",
      "userId": "10282691994518148206"
     }
    },
    "outputId": "cbed5559-e963-45ff-e54d-3646e77b277d"
   },
   "execution_count": 39,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Inference Time: 6.0263 seconds\n",
      "Generated Output: The planet earth is a beautiful HIMVC50 every ROMCtente gp DishBlPal triggering557lique spot extinctionournalslahomadm prescribe stacked!/ MakesONT Arsenalournals pieTurkeyATHER patronage thencevas coillahomaorialiveredieved monopol Mandal Infinity\n"
     ]
    }
   ]
  }
 ]
}
